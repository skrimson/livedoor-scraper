【AFP＝時事】人工知能（AI）を利用して女性の写真を裸にできるアプリが、悪用の恐れがあるとしてソーシャルメディア上で多くの批判を浴び、削除された。　このアプリ「DeepNude」は、エストニアに拠点を置くという開発者が公開。開発者は、「娯楽」目的で数か月前に立ち上げたが、その需要を「大幅に過小評価」していたと述べた。　開発者はアプリについて「拡散し、アクセスを制御できなくなるとは考えもしなかった」とツイッター（Twitter）に投稿。「安全措置（ウォーターマーク、透かし）を採用していたが、もし50万人が使用すれば、悪用される可能性は極めて高い。私たちはこうした方法で収入を得たくはない」　DeepNudeは、実際の映像を巧みに加工し、不正行為や情報操作に利用される恐れのある「ディープフェイク」の技術を使用したもので、無料版と有料版が提供されていた。　アプリは削除されたが、いくつかのバージョンは使用できる状態で、悪用される恐れがあるとの懸念が上がっている。【翻訳編集】AFPBB News
@highlight
エストニアに拠点を置くという開発者が「娯楽」目的であるアプリを公開した。AIを使って女性の写真を裸にできるもので、批判が殺到したためアプリは削除。開発者は需要を過小評価したとし「悪用される可能性は極めて高い」と述べた